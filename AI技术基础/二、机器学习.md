## 机器学习概念速览

### 1) 核心概念与原理
- **机器学习（Machine Learning）**：让模型从数据中“学出规律”，用来对新数据做预测/决策，而不是靠人手写死规则。
- **数据集与样本**：数据集由很多样本组成；每个样本通常是一行数据。
- **特征（Feature）**：输入给模型的变量/属性，比如“身高、体重、年龄”。
- **标签（Label）**：监督学习里要预测的目标，比如“是否患病”“房价”。
- **模型（Model）**：把特征映射到输出的函数/结构（线性模型、树模型、神经网络、深度学习等）。
- **训练（Training）**：用训练数据调整模型参数，让模型在训练集上表现更好。
- **预测/推理（Inference）**：训练好后，用模型对新样本输出结果。
- **损失函数（Loss）**：衡量“预测错了多少”的指标，训练的目标通常是让损失尽量小。
- **泛化（Generalization）**：模型在没见过的新数据上的表现能力，是机器学习最关心的点。

---

### 2) 常见算法类型

#### 2.1 监督学习
- **是什么**：有“输入（特征）—输出（标签）”成对的数据，学会从特征预测标签。
- **典型任务**：
  - **分类**：输出是类别（垃圾/非垃圾、猫/狗）
  - **回归**：输出是连续值（房价、温度）
- **常见算法**：线性/逻辑回归、SVM、决策树/随机森林、梯度提升树（XGBoost/LightGBM）、神经网络等。

#### 2.2 无监督学习
- **是什么**：只有特征，没有明确标签；目标是发现数据内部结构或模式。
- **典型任务**：
  - **聚类**：把相似样本分组（用户分群）
  - **降维**：用更少维度表达数据（可视化、压缩、去噪）
  - **异常检测**：找“很不一样”的点（欺诈/故障）
- **常见算法**：K-means、层次聚类、DBSCAN、PCA、t-SNE/UMAP（更多用于可视化）、自编码器等。

#### 2.3 强化学习
- **是什么**：智能体（Agent）在环境中做动作，得到奖励（Reward），学习一套策略（Policy）来最大化长期累计奖励。
- **关键元素**：状态（State）、动作（Action）、奖励（Reward）、策略（Policy）。
- **典型场景**：游戏对弈、机器人控制、资源调度、推荐策略优化等。
- **常见算法**：Q-learning、SARSA、DQN、PPO、SAC…

---

### 3) 模型评估指标
不同任务用不同指标，核心是“怎么量化好坏”。

#### 分类常用
- **准确率 Accuracy**：预测对的比例（类别很不均衡时可能误导）。
- **精确率 Precision**：预测为正的里面有多少真是正（少误报）。
- **召回率 Recall**：真实为正的里面有多少被找出来（少漏报）。
- **F1**：Precision 和 Recall 的折中（适合需要平衡误报/漏报）。
- **AUC-ROC**：衡量整体区分正负样本的能力（阈值无关）。

#### 回归常用
- **MAE**：平均绝对误差（直观，抗极端值相对更好）。
- **MSE / RMSE**：平方误差/其平方根（对大误差更敏感）。
- **R²**：解释方差比例（越接近 1 越好，需结合场景理解）。

---

#### 聚类（Clustering）
- **有真值标签（外部指标）**：
  - **ARI**：聚类结果与真值分组一致性（校正随机）
  - **NMI**：聚类分组与真值标签的相关程度
- **无真值标签（内部指标）**：
  - **Silhouette**：簇内紧、簇间远越好
  - **DBI**：越小越好（簇更分离、更紧凑）
  - **CH**：越大越好（簇间/簇内方差比）

#### 降维 / 表征学习（PCA/UMAP/自编码器等）
- **重构误差**：还原输入的误差（越小越好，常用于自编码器）
- **邻域/结构保持**：低维空间是否保留原空间的“近邻关系”
- **下游任务表现**：用 embedding 做简单分类/回归，效果越好表示表征越有用（常用的“间接评估”）

#### 异常检测
- **有标注**：AUC-ROC、PR-AUC、Precision@K / Recall@K（偏“排序/检索”）
- **无标注**：抽样人工核查 + 线上业务指标（误报率、命中率等）

---

- **平均回报（Average Return / Episode Reward）**：每回合累计奖励的平均（核心指标）
- **成功率（Success Rate）**：任务是否完成（过关率/达标率）
- **样本效率（Sample Efficiency）**：达到同等水平需要多少交互数据（越少越好）
- **稳定性/方差**：不同随机种子训练结果波动大不大
- **安全/约束指标（如有）**：碰撞次数、违规率、超限次数等

---

#### 一句话记忆
- **监督学习**：看“预测准不准”（分类/回归指标）
- **无监督学习**：看“结构好不好 / 表征有没有用”（内部结构指标 + 下游效果）
- **强化学习**：看“长期收益高不高、学得快不快、稳不稳”

---

### 4) 过拟合与欠拟合
- **欠拟合（Underfitting）**：模型太简单或没学到规律，训练集和测试集都表现差。
- **过拟合（Overfitting）**：模型把训练数据“记住了”，训练集很好，但新数据变差（泛化差）。
- **常见直观信号**：
  - 过拟合：训练误差低、验证/测试误差高
  - 欠拟合：训练误差也高、验证/测试也高

---

### 5) 模型优化方法
目的：让模型泛化更好、性能更稳、训练更有效。

#### 数据层面
- **更多/更干净的数据**、处理缺失/异常
- **特征工程**：构造更有信息的特征
- **数据增强**：尤其在图像/音频/文本中常见

#### 训练与正则化
- **正则化（L1/L2）**：限制模型复杂度，减少过拟合
- **早停（Early Stopping）**：验证集不再提升就停止训练
- **Dropout / BatchNorm（深度学习常用）**

#### 模型与超参数
- 换更合适的模型结构（更强或更简单）
- **超参数搜索**：网格搜索、随机搜索、贝叶斯优化

#### 验证策略
- **训练/验证/测试划分**
- **交叉验证（Cross Validation）**：数据少时更稳健地评估

#### 集成学习
- 多模型组合（Bagging/Boosting/Stacking）提升稳定性与精度
